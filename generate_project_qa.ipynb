{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Project Q&A\n",
    "This notebook demonstrates how to generate question-answer pairs from a Git repository and optimize different NLP models for sentence transformation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Ensure you have the following packages installed:\n",
    "- git\n",
    "- pyyaml\n",
    "- transformers\n",
    "- nltk\n",
    "- pandas\n",
    "\n",
    "You can install them using the following command:\n",
    "```bash\n",
    "pip install gitpython pyyaml transformers nltk pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "import yaml\n",
    "import os\n",
    "import glob\n",
    "import logging\n",
    "from transformers import pipeline\n",
    "from nltk.tokenize import sent_tokenize, blankline_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Configuration\n",
    "Read the configuration file to get the necessary parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "# Example usage\n",
    "config_path = 'config.yaml'\n",
    "config = read_config(config_path)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Git Repository\n",
    "Clone the Git repository and read the files based on the provided patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_git_repo(repo_url, commit_id, patterns, max_files):\n",
    "    repo_dir = \"/tmp/repo\"  # Temporary directory to clone the repo\n",
    "    if os.path.exists(repo_dir):\n",
    "        os.system(f\"rm -rf {repo_dir}\")\n",
    "\n",
    "    logging.info(f\"Cloning repository {repo_url}\")\n",
    "    repo = git.Repo.clone_from(repo_url, repo_dir)\n",
    "    repo.git.checkout(commit_id)\n",
    "    \n",
    "    content = {}\n",
    "    file_count = 0\n",
    "    for pattern in patterns:\n",
    "        file_paths = glob.glob(os.path.join(repo_dir, pattern), recursive=True)\n",
    "        for file_path in file_paths:\n",
    "            if os.path.isdir(file_path):\n",
    "                continue  # Skip directories\n",
    "            if file_count >= max_files:\n",
    "                break\n",
    "            with open(file_path, 'r') as file:\n",
    "                content[file_path] = file.read()\n",
    "            file_count += 1\n",
    "            logging.info(f\"Read file: {file_path}\")\n",
    "        if file_count >= max_files:\n",
    "            break\n",
    "    \n",
    "    return content\n",
    "\n",
    "# Example usage\n",
    "repo_url = config['repo_url']\n",
    "commit_id = config['commit_id']\n",
    "patterns = config['patterns']\n",
    "max_files = config['max_files']\n",
    "repo_content = read_git_repo(repo_url, commit_id, patterns, max_files)\n",
    "repo_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Relevant Sections\n",
    "Extract relevant sections from the text based on keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relevant_sections(text, keywords):\n",
    "    sections = []\n",
    "    paragraphs = blankline_tokenize(text)\n",
    "    for paragraph in paragraphs:\n",
    "        for keyword in keywords:\n",
    "            if keyword.lower() in paragraph.lower():\n",
    "                sections.append(paragraph)\n",
    "                break\n",
    "    logging.info(f\"Extracted {len(sections)} relevant sections\")\n",
    "    return sections\n",
    "\n",
    "# Example usage\n",
    "combined_content = \"\\n\".join(repo_content.values())\n",
    "keywords = config['keywords']\n",
    "relevant_sections = extract_relevant_sections(combined_content, keywords)\n",
    "relevant_sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Relevant Sections\n",
    "Combine relevant sections for better context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_relevant_sections(sections):\n",
    "    combined_sections = []\n",
    "    current_section = \"\"\n",
    "    for section in sections:\n",
    "        if len(current_section) + len(section) < 4096:  # Increase token limit for better context\n",
    "            current_section += \" \" + section\n",
    "        else:\n",
    "            combined_sections.append(current_section.strip())\n",
    "            current_section = section\n",
    "    if current_section:\n",
    "        combined_sections.append(current_section.strip())\n",
    "    return combined_sections\n",
    "\n",
    "# Example usage\n",
    "combined_sections = combine_relevant_sections(relevant_sections)\n",
    "combined_sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Q&A Pairs\n",
    "Generate question-answer pairs using the specified model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_pairs(sections, project_name, questions, min_sentence_length, model_name):\n",
    "    \"\"\"\n",
    "    Generate question-answer pairs from the provided text sections.\n",
    "\n",
    "    Args:\n",
    "        sections (list of str): List of text sections to use as context for generating Q&A pairs.\n",
    "        project_name (str): Name of the project for which Q&A pairs are being generated.\n",
    "        questions (list of str): List of question templates to generate Q&A pairs.\n",
    "        min_sentence_length (int): Minimum length of the answer in terms of number of words.\n",
    "        model_name (str): The Huggingface model to use for question answering.\n",
    "\n",
    "    Returns:\n",
    "        list of dict: List of dictionaries containing question and answer pairs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the question-answering pipeline with the specified model\n",
    "    question_answerer = pipeline(\"question-answering\", model=model_name)\n",
    "\n",
    "    # List to hold the generated question-answer pairs\n",
    "    seed_examples = []\n",
    "    scores = []\n",
    "    \n",
    "    # Combine all sections to provide a richer context\n",
    "    context = \" \".join(sections)\n",
    "\n",
    "    # Iterate through each question template\n",
    "    for question_template in questions:\n",
    "        # Format the question with the project name\n",
    "        question = question_template.format(project_name=project_name)\n",
    "        best_answer = \"\"\n",
    "        best_score = 0.0\n",
    "\n",
    "        try:\n",
    "            # Get the answer from the pipeline\n",
    "            answer = question_answerer(question=question, context=context)\n",
    "            logging.info(f\"Processing question '{question}' with context length {len(context)}\")\n",
    "            logging.info(f\"Answer: {answer['answer']} with score {answer['score']}\")\n",
    "\n",
    "            # Update the best answer if it meets the criteria\n",
    "            if answer['score'] > best_score and len(answer['answer'].split()) >= min_sentence_length:\n",
    "                best_answer = answer['answer']\n",
    "                best_score = answer['score']\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing question '{question}' with context '{context}': {e}\")\n",
    "            continue\n",
    "\n",
    "        # Add the question-answer pair to the list if the answer is valid\n",
    "        if best_answer.strip() and len(best_answer.split()) >= min_sentence_length:\n",
    "            seed_examples.append({'question': question, 'answer': best_answer.strip()})\n",
    "            scores.append({'question': question, 'answer': best_answer.strip(), 'score': best_score})\n",
    "        else:\n",
    "            logging.warning(f\"Skipped question '{question}' due to insufficient answer length. Answer: '{best_answer}', Length: {len(best_answer.split())}\")\n",
    "\n",
    "    return seed_examples, scores\n",
    "\n",
    "# Example usage\n",
    "project_name = config['project_name']\n",
    "questions = config['questions']\n",
    "min_sentence_length = config['min_sentence_length']\n",
    "model_name = config['model_name']\n",
    "seed_examples, scores = generate_qa_pairs(combined_sections, project_name, questions, min_sentence_length, model_name)\n",
    "seed_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Scores to CSV\n",
    "Save the scores of the generated Q&A pairs to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_scores_to_csv(scores, model_name):\n",
    "    df = pd.DataFrame(scores)\n",
    "    csv_path = f'scores_{model_name.replace(\"/\", \"_\")}.csv'\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    logging.info(f\"Scores saved to {csv_path}\")\n",
    "\n",
    "# Example usage\n",
    "save_scores_to_csv(scores, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Taxonomy\n",
    "Validate the taxonomy using the `ilab diff` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_taxonomy():\n",
    "    result = os.system(\"ilab diff\")\n",
    "    if result != 0:\n",
    "        logging.error(\"Taxonomy validation failed.\")\n",
    "        raise ValueError(\"Taxonomy validation failed.\")\n",
    "    else:\n",
    "        logging.info(\"Taxonomy is valid.\")\n",
    "\n",
    "# Example usage\n",
    "validate_taxonomy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate YAML File\n",
    "Generate the YAML file with the extracted Q&A pairs and other metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_yaml(repo_url, commit_id, patterns, yaml_path, project_name, questions, max_files, max_lines, keywords, min_sentence_length, min_answers, taxonomy_dir, model_name, save_scores):\n",
    "    logging.info(\"Starting YAML generation process\")\n",
    "    repo_content = read_git_repo(repo_url, commit_id, patterns, max_files)\n",
    "    combined_content = \"\"\n",
    "\n",
    "    for file_path, file_content in repo_content.items():\n",
    "        lines = file_content.split('\\n')\n",
    "        combined_content += \"\\n\".join(lines[:max_lines]) + \"\\n\"\n",
    "        if len(combined_content.split('\\n')) >= max_lines:\n",
    "            break\n",
    "\n",
    "    # Extract relevant sections based on keywords\n",
    "    relevant_sections = extract_relevant_sections(combined_content, keywords)\n",
    "\n",
    "    # Combine relevant sections for better context\n",
    "    combined_sections = combine_relevant_sections(relevant_sections)\n",
    "\n",
    "    # Generate seed examples from the relevant sections\n",
    "    seed_examples, scores = generate_qa_pairs(combined_sections, project_name, questions, min_sentence_length, model_name)\n",
    "\n",
    "    # Check if the minimum number of answers is met\n",
    "    if len(seed_examples) < min_answers:\n",
    "        logging.error(f\"Failed to generate the minimum required number of answers ({min_answers}).\")\n",
    "        raise ValueError(f\"Failed to generate the minimum required number of answers ({min_answers}).\")\n",
    "\n",
    "    document_content = {\n",
    "        'created_by': f'{project_name.lower()}-team',\n",
    "        'domain': project_name.lower(),\n",
    "        'seed_examples': seed_examples,\n",
    "        'task_description': f'Details on {project_name.lower()} community project',\n",
    "        'document': {\n",
    "            'repo': repo_url,\n",
    "            'commit': commit_id,\n",
    "            'patterns': patterns\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Define taxonomy path based on project name\n",
    "    taxonomy_path = os.path.join(taxonomy_dir, 'knowledge', project_name.lower(), 'overview')\n",
    "    os.makedirs(taxonomy_path, exist_ok=True)\n",
    "    yaml_file_path = os.path.join(taxonomy_path, yaml_path)\n",
    "\n",
    "    with open(yaml_file_path, 'w') as yaml_file:\n",
    "        yaml.dump(document_content, yaml_file, default_flow_style=False)\n",
    "    \n",
    "    logging.info(f\"YAML file generated at: {yaml_file_path}\")\n",
    "\n",
    "    # Save scores to CSV if required\n",
    "    if save_scores:\n",
    "        save_scores_to_csv(scores, model_name)\n",
    "\n",
    "    # Validate taxonomy\n",
    "    validate_taxonomy()\n",
    "\n",
    "    # Generate synthetic data\n",
    "    # generate_synthetic_data()\n",
    "\n",
    "# Example usage\n",
    "repo_url = config['repo_url']\n",
    "commit_id = config['commit_id']\n",
    "patterns = config['patterns']\n",
    "yaml_path = config['yaml_path']\n",
    "project_name = config['project_name']\n",
    "questions = config['questions']\n",
    "max_files = config['max_files']\n",
    "max_lines = config['max_lines']\n",
    "keywords = config['keywords']\n",
    "min_sentence_length = config['min_sentence_length']\n",
    "min_answers = config['min_answers']\n",
    "taxonomy_dir = config['taxonomy_dir']\n",
    "model_name = config['model_name']\n",
    "save_scores = True  # Set to True to save scores\n",
    "\n",
    "generate_yaml(repo_url, commit_id, patterns, yaml_path, project_name, questions, max_files, max_lines, keywords, min_sentence_length, min_answers, taxonomy_dir, model_name, save_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
